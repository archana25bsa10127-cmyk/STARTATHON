ğŸš— Off-Road Semantic Segmentation using DeepLabV3+
ğŸ“Œ Project Overview

This project focuses on semantic segmentation of off-road environments for autonomous navigation and terrain understanding. 
The goal is to accurately classify each pixel in an image into predefined terrain categories such as trees, bushes, rocks, sky, and ground clutter.
We implemented a DeepLabV3+ model with a pretrained backbone and optimized it using advanced data augmentation strategies and a hybrid loss function.
Through iterative experimentation and systematic performance evaluation, we improved the Intersection over Union (IoU) score from an initial baseline
of [Baseline IoU] to a final score of [Final IoU], demonstrating strong segmentation performance and improved generalization capability.

ğŸ¯ Objectives

Perform pixel-level classification for 10 terrain classes
Improve IoU score through experimentation
Handle class imbalance effectively
Ensure model generalizes to unseen off-road scenes
Maintain computational efficiency

ğŸ§  Model Architecture

ğŸ”¹ Base Model
Architecture: DeepLabV3+
Backbone: Pretrained CNN backbone (ResNet / MobileNet)
Pretraining: ImageNet
ğŸ”¹ Custom Modifications

Hybrid loss function:
Cross-Entropy Loss
Dice Loss
Class-weighted loss to handle imbalance
Strong data augmentation pipeline

ğŸ”¹ Input Configuration
Image Resolution: 448 Ã— 448
Number of Classes: 10
Optimizer: Adam
Learning Rate: 5e-5
Batch Size: 2
Epochs: 20



ğŸš€ Key Improvement
Improved Mean IoU from [Baseline IoU] â†’ [Final IoU]
Better boundary detection
Reduced misclassification in small-object classes
Improved performance on underrepresented classes

ğŸ§ª Training Strategy
Data Augmentation
Random Horizontal Flip
Color Jitter (Brightness, Contrast, Saturation)
Random Resizing
Normalization
Loss Function

We used a Hybrid Loss:

Total Loss = CrossEntropy + Dice Loss

This allowed:

Better class separation (CrossEntropy)
Improved overlap quality (Dice)


ğŸ“ˆ Evaluation Metrics

The following metrics were used:
Mean Intersection over Union (IoU) (Primary Metric)
Dice Coefficient
Pixel Accuracy
IoU was used as the primary evaluation benchmark.

ğŸ“‚ Dataset Structure
Dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ Color_Images/
â”‚   â””â”€â”€ Segmentation/
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ Color_Images/
â”‚   â””â”€â”€ Segmentation/
â””â”€â”€ test/
    â”œâ”€â”€ Color_Images/
    â””â”€â”€ Segmentation/

Training outputs:
Model weights
Loss curves
IoU curves
Dice curves
Pixel accuracy curves
Evaluation logs

Output:
Mean IoU on Test Set: [Final IoU]

ğŸ† Key Highlights

Pretrained backbone for strong feature extraction
Hybrid loss for improved segmentation overlap
Class imbalance handled using weighted loss
Extensive metric tracking and visualization
Hackathon-ready modular codebase

ğŸ“ŠResult and Performance
To systematically evaluate our improvements, we conducted four experimental runs, progressively enhancing the model with data augmentation and optimization strategies.

ğŸ” Observation 1 â€“ Baseline Model
-DeepLabV3+ with pretrained backbone
-Standard preprocessing
-Cross-Entropy loss
-No augmentation
IoU Score: 0.2130
Analysis:
The baseline model achieved an IoU of 0.2130, indicating limited generalization and highlighting the domain gap challenge.

ğŸ” Observation 2 â€“ Data Augmentation Applied
-Rotation, flipping, scaling
-Brightness and contrast adjustments
-Noise and blur augmentation
-IoU Score: 0.2870
Analysis:
Applying augmentation significantly improved robustness and generalization.

ğŸ“ˆ Improvement from Baseline:
0.2130 â†’ 0.2870
â‰ˆ 30.45% relative improvement

ğŸ” Observation 3 â€“ Augmentation + Optimizating
-Hybrid loss (Cross-Entropy + IoU-based loss)
-Lightweight backbone
-Hyperparameter tuning
IoU Score: 0.2930
Analysis:
Further optimization improved model stability and inference efficiency.

ğŸ“ˆ Improvement from Baseline:
0.2130 â†’ 0.2930
â‰ˆ 33.18% relative improvement

ğŸ” Observation 4 â€“ Final Fine-Tuned Model
-Refined hyperparameter tuning
-Improved training stability
-Better convergence strategy
IoU Score: 0.2941
Analysis:
The final configuration achieved the highest IoU of 0.2941, representing the best overall performance. While the increase over Observation 3 is incremental, it reflects improved model refinement and consistent convergence behavior.

ğŸ“ˆ Overall Improvement from Baseline:
0.2130 â†’ 0.2941
â‰ˆ 33.68% relative improvement

ğŸ” Key Insight
-Major improvement came from data augmentation.
-Optimization strategies provided incremental but important performance gains.
-Fine-tuning improved model stability and convergence consistency.

ğŸ“Œ Future Improvements

Add attention-based refinement module
Experiment with larger backbone (ResNet101)
Apply Test-Time Augmentation
Use focal loss for rare classes
Try transformer-based segmentation models
ğŸ‘¨â€ğŸ’» Team
Developed for Off-Road Semantic Segmentation Hackathon.
